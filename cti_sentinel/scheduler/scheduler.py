"""
Scheduler - Automatisation des t√¢ches CTI Sentinel.
G√®re la collecte p√©riodique, le traitement, les alertes, backups et nettoyage.
"""

import asyncio
import logging
import signal
import sys
from datetime import datetime, timezone
from typing import Optional

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

from cti_sentinel.config import ConfigLoader
from cti_sentinel.database.manager import DatabaseManager
from cti_sentinel.collectors.engine import CollectionEngine
from cti_sentinel.processor.engine import ProcessingEngine
from cti_sentinel.analyzer.correlation import CorrelationEngine
from cti_sentinel.alerts.manager import AlertManager

logger = logging.getLogger(__name__)


class CTIScheduler:
    """Planificateur de t√¢ches automatis√©es CTI Sentinel."""

    def __init__(self, config: Optional[ConfigLoader] = None):
        self.config = config or ConfigLoader()
        self.db = DatabaseManager(self.config)
        self.db.create_tables()

        self.collection_engine = CollectionEngine(self.config, self.db)
        self.processing_engine = ProcessingEngine(self.config, self.db)
        self.correlation_engine = CorrelationEngine(self.config, self.db)
        self.alert_manager = AlertManager(self.config, self.db)

        self.scheduler = AsyncIOScheduler(
            timezone="UTC",
            job_defaults={
                "coalesce": True,
                "max_instances": 1,
                "misfire_grace_time": 300,
            },
        )
        self._running = False

    # ========================================================================
    # T√¢ches planifi√©es
    # ========================================================================

    async def task_collect_high_frequency(self):
        """Collecte haute fr√©quence (toutes les 30 min) - RSS critiques."""
        logger.info("‚è∞ [Scheduler] Collecte haute fr√©quence d√©marr√©e")
        try:
            await self.collection_engine.collect_all(categories=["cert", "news"])
            logger.info("‚úÖ [Scheduler] Collecte haute fr√©quence termin√©e")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur collecte haute fr√©quence: {e}")

    async def task_collect_medium_frequency(self):
        """Collecte moyenne fr√©quence (toutes les 2h) - APIs vuln√©rabilit√©s."""
        logger.info("‚è∞ [Scheduler] Collecte moyenne fr√©quence d√©marr√©e")
        try:
            await self.collection_engine.collect_all(categories=["vulnerability", "threat_intel"])
            logger.info("‚úÖ [Scheduler] Collecte moyenne fr√©quence termin√©e")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur collecte moyenne fr√©quence: {e}")

    async def task_collect_low_frequency(self):
        """Collecte basse fr√©quence (toutes les 6h) - Bases CTI compl√®tes."""
        logger.info("‚è∞ [Scheduler] Collecte basse fr√©quence d√©marr√©e")
        try:
            await self.collection_engine.collect_all(categories=["mitre", "abuse_ch"])
            logger.info("‚úÖ [Scheduler] Collecte basse fr√©quence termin√©e")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur collecte basse fr√©quence: {e}")

    async def task_process_articles(self):
        """Traitement LLM des articles en attente."""
        logger.info("ü§ñ [Scheduler] Traitement des articles d√©marr√©")
        try:
            limit = self.config.get("scheduler.processing_batch_size", 50)
            await self.processing_engine.process_pending_articles(limit=limit)
            logger.info("‚úÖ [Scheduler] Traitement des articles termin√©")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur traitement: {e}")

    async def task_evaluate_alerts(self):
        """√âvaluation des alertes sur les nouveaux articles."""
        logger.info("üîî [Scheduler] √âvaluation des alertes d√©marr√©e")
        try:
            from cti_sentinel.database.models import Article, ArticleStatus
            with self.db.get_session() as session:
                # Articles trait√©s non encore √©valu√©s pour alertes
                recent = (
                    session.query(Article)
                    .filter(Article.status == ArticleStatus.processed)
                    .order_by(Article.collected_at.desc())
                    .limit(100)
                    .all()
                )
                for article in recent:
                    await self.alert_manager.evaluate_article(session, article)
            logger.info(f"‚úÖ [Scheduler] {len(recent)} articles √©valu√©s pour alertes")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur alertes: {e}")

    async def task_daily_digest(self):
        """Envoi du digest quotidien."""
        logger.info("üìß [Scheduler] Envoi du digest quotidien")
        try:
            with self.db.get_session() as session:
                await self.alert_manager.send_daily_digest(session)
            logger.info("‚úÖ [Scheduler] Digest quotidien envoy√©")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur digest: {e}")

    async def task_backup(self):
        """Backup quotidien de la base de donn√©es."""
        logger.info("üíæ [Scheduler] Backup d√©marr√©")
        try:
            backup_path = self.db.backup()
            logger.info(f"‚úÖ [Scheduler] Backup cr√©√©: {backup_path}")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur backup: {e}")

    async def task_cleanup(self):
        """Nettoyage hebdomadaire des donn√©es anciennes."""
        logger.info("üßπ [Scheduler] Nettoyage d√©marr√©")
        try:
            retention_days = self.config.get("scheduler.retention_days", 90)
            with self.db.get_session() as session:
                deleted = self.db.cleanup_old_data(session, days=retention_days)
            logger.info(f"‚úÖ [Scheduler] Nettoyage termin√©: {deleted} entr√©es supprim√©es")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur nettoyage: {e}")

    async def task_enrich_vulnerabilities(self):
        """Enrichissement EPSS/CISA KEV des vuln√©rabilit√©s."""
        logger.info("üîç [Scheduler] Enrichissement des vuln√©rabilit√©s d√©marr√©")
        try:
            from cti_sentinel.database.models import Vulnerability
            with self.db.get_session() as session:
                vulns = (
                    session.query(Vulnerability)
                    .filter(Vulnerability.epss_score == None)
                    .limit(50)
                    .all()
                )
                for vuln in vulns:
                    await self.processing_engine.enrich_vulnerability(session, vuln)
            logger.info(f"‚úÖ [Scheduler] {len(vulns)} vuln√©rabilit√©s enrichies")
        except Exception as e:
            logger.error(f"‚ùå [Scheduler] Erreur enrichissement: {e}")

    # ========================================================================
    # Configuration du scheduler
    # ========================================================================

    def setup_jobs(self):
        """Configure tous les jobs planifi√©s."""
        sched_config = self.config.get("scheduler", {})

        # Collecte haute fr√©quence - toutes les 60 min (respectueux des serveurs)
        high_freq = sched_config.get("high_frequency_minutes", 60)
        self.scheduler.add_job(
            self.task_collect_high_frequency,
            IntervalTrigger(minutes=high_freq),
            id="collect_high",
            name="Collecte haute fr√©quence",
        )

        # Collecte moyenne fr√©quence - toutes les 2h
        med_freq = sched_config.get("medium_frequency_minutes", 120)
        self.scheduler.add_job(
            self.task_collect_medium_frequency,
            IntervalTrigger(minutes=med_freq),
            id="collect_medium",
            name="Collecte moyenne fr√©quence",
        )

        # Collecte basse fr√©quence - toutes les 6h
        low_freq = sched_config.get("low_frequency_minutes", 360)
        self.scheduler.add_job(
            self.task_collect_low_frequency,
            IntervalTrigger(minutes=low_freq),
            id="collect_low",
            name="Collecte basse fr√©quence",
        )

        # Traitement LLM - toutes les 15 min
        process_freq = sched_config.get("processing_frequency_minutes", 15)
        self.scheduler.add_job(
            self.task_process_articles,
            IntervalTrigger(minutes=process_freq),
            id="process",
            name="Traitement LLM",
        )

        # Alertes - toutes les 10 min
        alert_freq = sched_config.get("alert_frequency_minutes", 10)
        self.scheduler.add_job(
            self.task_evaluate_alerts,
            IntervalTrigger(minutes=alert_freq),
            id="alerts",
            name="√âvaluation alertes",
        )

        # Digest quotidien - 08:00 UTC
        digest_hour = sched_config.get("digest_hour", 8)
        self.scheduler.add_job(
            self.task_daily_digest,
            CronTrigger(hour=digest_hour, minute=0),
            id="digest",
            name="Digest quotidien",
        )

        # Enrichissement vuln√©rabilit√©s - toutes les 4h
        self.scheduler.add_job(
            self.task_enrich_vulnerabilities,
            IntervalTrigger(hours=4),
            id="enrich_vulns",
            name="Enrichissement vuln√©rabilit√©s",
        )

        # Backup quotidien - 02:00 UTC
        backup_hour = sched_config.get("backup_hour", 2)
        self.scheduler.add_job(
            self.task_backup,
            CronTrigger(hour=backup_hour, minute=0),
            id="backup",
            name="Backup quotidien",
        )

        # Nettoyage hebdomadaire - dimanche 03:00 UTC
        self.scheduler.add_job(
            self.task_cleanup,
            CronTrigger(day_of_week="sun", hour=3, minute=0),
            id="cleanup",
            name="Nettoyage hebdomadaire",
        )

        logger.info(f"üìã {len(self.scheduler.get_jobs())} jobs planifi√©s configur√©s")

    # ========================================================================
    # Gestion du cycle de vie
    # ========================================================================

    async def start(self, run_initial_collection: bool = True):
        """D√©marre le scheduler."""
        logger.info("üöÄ D√©marrage de CTI Sentinel Scheduler...")

        self.setup_jobs()
        self.scheduler.start()
        self._running = True

        # Collecte initiale au d√©marrage
        if run_initial_collection:
            logger.info("üîÑ Collecte initiale au d√©marrage...")
            await self.task_collect_high_frequency()
            await self.task_process_articles()
            await self.task_evaluate_alerts()

        logger.info("‚úÖ CTI Sentinel Scheduler en cours d'ex√©cution")

        # Afficher les jobs planifi√©s
        for job in self.scheduler.get_jobs():
            next_run = job.next_run_time
            logger.info(f"  üìå {job.name} ‚Üí Prochaine ex√©cution: {next_run}")

    async def stop(self):
        """Arr√™te le scheduler proprement."""
        logger.info("‚èπÔ∏è Arr√™t de CTI Sentinel Scheduler...")
        self._running = False
        self.scheduler.shutdown(wait=True)
        logger.info("‚úÖ Scheduler arr√™t√© proprement")

    def get_status(self) -> dict:
        """Retourne le statut du scheduler."""
        jobs = []
        for job in self.scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run": str(job.next_run_time) if job.next_run_time else None,
                "pending": job.pending,
            })
        return {
            "running": self._running,
            "jobs": jobs,
            "job_count": len(jobs),
        }


# ============================================================================
# Point d'entr√©e CLI
# ============================================================================

async def run_scheduler():
    """Ex√©cute le scheduler en mode daemon."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler("logs/scheduler.log"),
        ],
    )

    scheduler = CTIScheduler()
    loop = asyncio.get_event_loop()

    def shutdown_handler(sig, frame):
        logger.info(f"Signal {sig} re√ßu, arr√™t en cours...")
        loop.create_task(scheduler.stop())

    signal.signal(signal.SIGINT, shutdown_handler)
    signal.signal(signal.SIGTERM, shutdown_handler)

    await scheduler.start()

    # Maintenir le processus actif
    try:
        while scheduler._running:
            await asyncio.sleep(1)
    except (KeyboardInterrupt, SystemExit):
        await scheduler.stop()


if __name__ == "__main__":
    asyncio.run(run_scheduler())
